{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>length</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "\n",
       "   length  toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0     264      0             0        0       0       0              0  \n",
       "1     112      0             0        0       0       0              0  \n",
       "2     233      0             0        0       0       0              0  \n",
       "3     622      0             0        0       0       0              0  \n",
       "4      67      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "col = list(df.columns)\n",
    "df['length'] = df.comment_text.apply(lambda x : len(x))\n",
    "df = df[col[:2]+ ['length'] + col[2:]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic            9.584448\n",
      "severe_toxic     0.999555\n",
      "obscene          5.294822\n",
      "threat           0.299553\n",
      "insult           4.936361\n",
      "identity_hate    0.880486\n",
      "Name: mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.describe().loc['mean'].iloc[1:]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "기본적으로 데이터를 살펴보면, 각 클레스는 대략적으로 10% 미만으로 1로 라벨링이 된 것을 확인할 수 있다.  \n",
    "모든 클래스에 대해서 데이터의 불균형이 심한 상태이다.  \n",
    "Imbalance를 고려하여 Loss에 가중치를 주어서 트레이닝 시킨다.  \n",
    "기본적인 cross-entropy Loss 에서 label 이 1일 때의 가중치(w>=1)를 주어 Recall을 증가시킬 수 있도록 하자.  \n",
    "여러 가중치를 실험해본다.\n",
    "\n",
    "기본적인 전략은 각 클래스별로 모델을 학습시켜 Classify 하는 것이다.  \n",
    "다음과 같은 방법을 적용하여 문제를 해결해 볼 것이다.\n",
    "\n",
    "\n",
    "    1. Sentence embedding -> dense network \n",
    "        1-1 : LSTM \n",
    "        1-2 : Conv\n",
    "        \n",
    "    2. Attention Layer로 구성한 Model을 통해 각각의 클래스 마다 모델을 만들어 예측하는 전략을 취한다.     \n",
    "    3. SVM\n",
    "    4. Decision Tree / Random forest\n",
    "    5. Ensenble\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13699\n",
      "1595\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df[(df.toxic == 1) & (df.severe_toxic == 0)]))\n",
    "print(len(df[(df.toxic == 1) & (df.severe_toxic == 1)]))\n",
    "print(len(df[(df.toxic == 0) & (df.severe_toxic == 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 severe_toxic class는 항상 toxic class인 경우에만 성립하므로  \n",
    "toxic을 classify한 이후에 severe_toxic class를 classify 하도록 training 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 의미의 단어이되 인칭의 변화 등 문법적인 이유로 형태가 다른 단어들을 같은 형태로 변환시켜준다.  \n",
    "여기에는 대문자를 소문자로 바꾸는 것도 포함된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'] = df.comment_text.apply(lambda text: ' '.join(map(lambda word: stemmer.stem(word), re.split(' |\\n', text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>length</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explan whi the edit made under my usernam hard...</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d'aww! he match this background colour i'm see...</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man, i'm realli not tri to edit war. it ju...</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" more i can't make ani real suggest on improv...</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you, sir, are my hero. ani chanc you rememb wh...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  0000997932d777bf  explan whi the edit made under my usernam hard...   \n",
       "1  000103f0d9cfb60f  d'aww! he match this background colour i'm see...   \n",
       "2  000113f07ec002fd  hey man, i'm realli not tri to edit war. it ju...   \n",
       "3  0001b41b1c6bb37e  \" more i can't make ani real suggest on improv...   \n",
       "4  0001d958c54c6e35  you, sir, are my hero. ani chanc you rememb wh...   \n",
       "\n",
       "   length  toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0     264      0             0        0       0       0              0  \n",
       "1     112      0             0        0       0       0              0  \n",
       "2     233      0             0        0       0       0              0  \n",
       "3     622      0             0        0       0       0              0  \n",
       "4      67      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Method of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 사용된 샘플에서의 feature의 수(# of voca)가 매우 많기 때문에 임베딩이 필요하다.  \n",
    "다음과 같은 두가지 방법을 이용하여 접근하여 보자.\n",
    "\n",
    "> 1. Embedding layer를 포함한 Model을 Training \n",
    "> 2. Word2Vec을 이용한 Pretrained embedding layer를 사용하여 Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of voca: 420953\n"
     ]
    }
   ],
   "source": [
    "print('# of voca: {}'.format(len(set([word for doc in df.comment_text for word in doc.split(' ')]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 구조는 길이가 지나치게 긴 문장에 대해 Backpropagation이 잘 이루어지지 않으므로, 문장 길이를 제한한다.  \n",
    "문장길이의 분포를 살펴보면, 대부분이 1000자 이하의 글자로 구성되어 있으므로 1000자 이하의 표본을 이용하여 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dd0fc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wMA/QIwwkieigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c46c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.length.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length <= 1000 : 146211\n",
      "length >  1000 : 13360\n"
     ]
    }
   ],
   "source": [
    "print('length <= 1000 : {}'.format(sum(df.length<=1000)))\n",
    "print('length >  1000 : {}'.format(sum(df.length>1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.length<=1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평균적으로 한 Document 당 vocab의 분포와 평균적인 개수는 다음과 같다.  \n",
    "RNN의 Batch sequence length를 200으로 설정하고 Dataset을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균적인 vocab의 숫자 : 70.39\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGF5JREFUeJzt3X/wXXV95/Hny0RQW5EgwbIEm6gZ\n28jYFVPMrF23KzUEbA3uSBe2s2SRbXYtbnV3OzWo0zgqM9BtpTKrbFGyBtaKiFqya9g0oq3TGX4F\nQX6K+QosfIVCNBFoUSj43j/u56vXcJPc7/eb871y83zM3LnnvM/nnPM5Z77fvHLO/XzPTVUhSVKX\nnjPqDkiSxp9hI0nqnGEjSeqcYSNJ6pxhI0nqnGEjSeqcYSNJ6pxhI0nqnGEjSerc/FF34GfF4Ycf\nXosXLx51NyTpWeXGG2/8blUt3Fc7w6ZZvHgx27ZtG3U3JOlZJcn/G6adt9EkSZ0zbCRJnTNsJEmd\nM2wkSZ0zbCRJnTNsJEmdM2wkSZ0zbCRJnTNsJEmd8wkC+8HidV8a2b7vPffNI9u3JA3LKxtJUucM\nG0lS5wwbSVLnDBtJUucMG0lS5wwbSVLnDBtJUucMG0lS5wwbSVLnDBtJUuc6C5skG5I8nOS2Acv+\nIEklObzNJ8kFSSaS3JLk2L62a5Jsb681ffXXJrm1rXNBkrT6YUm2tvZbkyzo6hglScPp8srmU8Cq\n3YtJjgbeBNzXVz4RWNpea4ELW9vDgPXA64DjgPV94XFhazu13tS+1gFXV9VS4Oo2L0kaoc7Cpqq+\nBuwcsOh84A+B6qutBi6pnmuBQ5McCZwAbK2qnVW1C9gKrGrLDqmqa6qqgEuAk/u2tbFNb+yrS5JG\nZE4/s0nyFuA7VfWN3RYdBdzfNz/ZanurTw6oA7ykqh4EaO9H7LcDkCTNyJx9xUCSFwDvA1YOWjyg\nVjOoT7dPa+ndiuOlL33pdFeXJA1pLq9sXg4sAb6R5F5gEfD1JL9A78rk6L62i4AH9lFfNKAO8FC7\nzUZ7f3hPHaqqi6pqeVUtX7hw4SwOTZK0N3MWNlV1a1UdUVWLq2oxvcA4tqr+DtgEnN5Gpa0AHmm3\nwLYAK5MsaAMDVgJb2rLHkqxoo9BOB65su9oETI1aW9NXlySNSJdDnz8DXAO8MslkkjP30nwzcDcw\nAXwC+D2AqtoJfAi4ob0+2GoA7wA+2db5NnBVq58LvCnJdnqj3s7dn8clSZq+zj6zqarT9rF8cd90\nAWftod0GYMOA+jbgmAH17wHHT7O7kqQO+QQBSVLnDBtJUucMG0lS5wwbSVLnDBtJUucMG0lS5wwb\nSVLnDBtJUucMG0lS5wwbSVLnDBtJUucMG0lS5wwbSVLnDBtJUucMG0lS5wwbSVLnDBtJUucMG0lS\n5wwbSVLnOgubJBuSPJzktr7af0vyzSS3JPlikkP7lp2dZCLJXUlO6KuvarWJJOv66kuSXJdke5LP\nJjmo1Q9u8xNt+eKujlGSNJwur2w+BazarbYVOKaqXg18CzgbIMky4FTgVW2djyeZl2Qe8DHgRGAZ\ncFprC3AecH5VLQV2AWe2+pnArqp6BXB+aydJGqHOwqaqvgbs3K32V1X1VJu9FljUplcDl1XVE1V1\nDzABHNdeE1V1d1U9CVwGrE4S4I3AFW39jcDJfdva2KavAI5v7SVJIzLKz2zeDlzVpo8C7u9bNtlq\ne6q/GPh+X3BN1X9qW235I639MyRZm2Rbkm07duyY9QFJkgYbSdgkeR/wFPDpqdKAZjWD+t629cxi\n1UVVtbyqli9cuHDvnZYkzdj8ud5hkjXAbwLHV9VUCEwCR/c1WwQ80KYH1b8LHJpkfrt66W8/ta3J\nJPOBF7Hb7TxJ0tya0yubJKuA9wBvqarH+xZtAk5tI8mWAEuB64EbgKVt5NlB9AYRbGoh9VXgbW39\nNcCVfdta06bfBnylL9QkSSPQ2ZVNks8Avw4cnmQSWE9v9NnBwNb2mf21VfUfq+r2JJcDd9C7vXZW\nVT3dtvNOYAswD9hQVbe3XbwHuCzJh4GbgItb/WLg0iQT9K5oTu3qGCVJw+ksbKrqtAHliwfUptqf\nA5wzoL4Z2Dygfje90Wq7138InDKtzkqSOuUTBCRJnTNsJEmdM2wkSZ0zbCRJnTNsJEmdM2wkSZ0z\nbCRJnTNsJEmdM2wkSZ0zbCRJnTNsJEmdM2wkSZ0zbCRJnTNsJEmdM2wkSZ0zbCRJnTNsJEmdM2wk\nSZ3rLGySbEjycJLb+mqHJdmaZHt7X9DqSXJBkokktyQ5tm+dNa399iRr+uqvTXJrW+eCJNnbPiRJ\no9Pllc2ngFW71dYBV1fVUuDqNg9wIrC0vdYCF0IvOID1wOuA44D1feFxYWs7td6qfexDkjQinYVN\nVX0N2LlbeTWwsU1vBE7uq19SPdcChyY5EjgB2FpVO6tqF7AVWNWWHVJV11RVAZfstq1B+5Akjchc\nf2bzkqp6EKC9H9HqRwH397WbbLW91ScH1Pe2D0nSiPysDBDIgFrNoD69nSZrk2xLsm3Hjh3TXV2S\nNKS5DpuH2i0w2vvDrT4JHN3XbhHwwD7qiwbU97aPZ6iqi6pqeVUtX7hw4YwPSpK0d3MdNpuAqRFl\na4Ar++qnt1FpK4BH2i2wLcDKJAvawICVwJa27LEkK9ootNN329agfUiSRmR+VxtO8hng14HDk0zS\nG1V2LnB5kjOB+4BTWvPNwEnABPA4cAZAVe1M8iHghtbug1U1NejgHfRGvD0fuKq92Ms+JEkjMlTY\nJDmmqm7bd8ufqKrT9rDo+AFtCzhrD9vZAGwYUN8GHDOg/r1B+5Akjc6wt9H+R5Lrk/xekkM77ZEk\naewMFTZV9WvA79D7sH5bkr9I8qZOeyZJGhtDDxCoqu3A+4H3AP8CuCDJN5P8q646J0kaD0OFTZJX\nJzkfuBN4I/BbVfXLbfr8DvsnSRoDw45G++/AJ4D3VtUPpopV9UCS93fSM0nS2Bg2bE4CflBVTwMk\neQ7wvKp6vKou7ax3kqSxMOxnNl+m9/csU17QapIk7dOwYfO8qvr7qZk2/YJuuiRJGjfDhs0/7PaF\nZq8FfrCX9pIk/diwn9m8G/hckqmHXR4J/OtuuiRJGjdDhU1V3ZDkl4BX0nu8/zer6h877ZkkaWxM\n50Gcvwosbuu8JglVdUknvZIkjZVhH8R5KfBy4Gbg6Vae+jpmSZL2atgrm+XAsvZ0ZkmSpmXY0Wi3\nAb/QZUckSeNr2Cubw4E7klwPPDFVrKq3dNIrSdJYGTZsPtBlJyRJ423Yoc9/k+QXgaVV9eUkLwDm\ndds1SdK4GPYrBn4XuAL481Y6CvjLrjolSRovww4QOAt4PfAo/PiL1I6Y6U6T/Ocktye5Lclnkjwv\nyZIk1yXZnuSzSQ5qbQ9u8xNt+eK+7Zzd6nclOaGvvqrVJpKsm2k/JUn7x7Bh80RVPTk1k2Q+vb+z\nmbYkRwG/DyyvqmPo3Y47FTgPOL+qlgK7gDPbKmcCu6rqFfS+qO28tp1lbb1XAauAjyeZl2Qe8DHg\nRGAZcFprK0kakWHD5m+SvBd4fpI3AZ8D/vcs9ju/bWs+vadHP0jvWz+vaMs3Aie36dVtnrb8+CRp\n9cuq6omqugeYAI5rr4mqursF5GWtrSRpRIYNm3XADuBW4D8Am4EZfUNnVX0H+BPgPnoh8whwI/D9\nqnqqNZuk97kQ7f3+tu5Trf2L++u7rbOn+jMkWZtkW5JtO3bsmMnhSJKGMOxotB/R+1roT8x2h0kW\n0LvSWAJ8n95V0omDdju1yh6W7ak+KEAH3vKrqouAiwCWL1/u0xEkqSPDPhvtHgb8g11VL5vBPn8D\nuKeqdrRtfwH4Z8ChSea3q5dFwNTXGUwCRwOT7bbbi4CdffUp/evsqS5JGoHpPBttyvOAU4DDZrjP\n+4AV7W91fgAcD2wDvgq8jd5nLGuAK1v7TW3+mrb8K1VVSTYBf5HkI8A/AZYC19O74lmaZAnwHXqD\nCP7NDPsqSdoPhr2N9r3dSn+W5G+BP5ruDqvquiRXAF8HngJuoncr60vAZUk+3GoXt1UuBi5NMkHv\niubUtp3bk1wO3NG2c1ZVPQ2Q5J3AFnoj3TZU1e3T7ackaf8Z9jbasX2zz6F3pfPCme60qtYD63cr\n301vJNnubX9I70pq0HbOAc4ZUN9MbxCDJOlnwLC30f60b/op4F7gt/d7byRJY2nY22j/suuOSJLG\n17C30f7L3pZX1Uf2T3ckSeNoOqPRfpXeyDCA3wK+xk//8aQkSQNN58vTjq2qxwCSfAD4XFX9+646\nJkkaH8M+rualwJN9808Ci/d7byRJY2nYK5tLgeuTfJHekwTeClzSWa8kSWNl2NFo5yS5CvjnrXRG\nVd3UXbckSeNk2Nto0PsqgEer6qP0nlO2pKM+SZLGzLBfC70eeA9wdis9F/hfXXVKkjRehr2yeSvw\nFuAfAKrqAWbxuBpJ0oFl2LB5sqqK9jUDSX6uuy5JksbNsGFzeZI/p/edM78LfJn98EVqkqQDw7Cj\n0f4kyZuAR4FXAn9UVVs77ZkkaWzsM2ySzAO2VNVvAAaMJGna9nkbrX0h2eNJXjQH/ZEkjaFhnyDw\nQ+DWJFtpI9IAqur3O+mVJGmsDBs2X2ovSZKmba9hk+SlVXVfVW3cnztNcijwSeAYesOp3w7cBXyW\n3gM+7wV+u6p2JQnwUeAk4HHg31XV19t21gDvb5v98FQ/k7wW+BTwfHpfD/2uNnRbkjQC+/rM5i+n\nJpJ8fj/u96PA/62qXwJ+BbgTWAdcXVVLgavbPMCJwNL2Wgtc2PpzGLAeeB1wHLA+yYK2zoWt7dR6\nq/Zj3yVJ07SvsEnf9Mv2xw6THAK8AbgYoKqerKrvA6uBqSuojcDJbXo1cEn1XEvvb32OBE4AtlbV\nzqraRW+k3Kq27JCquqZdzVzSty1J0gjsK2xqD9Oz8TJgB/A/k9yU5JPtiQQvqaoHAdr7Ea39Ufz0\nN4JOttre6pMD6pKkEdlX2PxKkkeTPAa8uk0/muSxJI/OcJ/zgWOBC6vqNfRGt63bS/sMqNUM6s/c\ncLI2ybYk23bs2LH3XkuSZmyvYVNV86rqkKp6YVXNb9NT84fMcJ+TwGRVXdfmr6AXPg+1W2C094f7\n2h/dt/4i4IF91BcNqA86vouqanlVLV+4cOEMD0eStC/T+T6b/aKq/g64P8krW+l44A5gE7Cm1dYA\nV7bpTcDp6VkBPNJus20BViZZ0AYGrKT3pIMHgceSrGgj2U7v25YkaQSG/Tub/e0/AZ9OchBwN3AG\nveC7PMmZwH3AKa3tZnrDnifoDX0+A6Cqdib5EHBDa/fBqtrZpt/BT4Y+X9VekqQRGUnYVNXNwPIB\ni44f0LaAs/awnQ3AhgH1bfT+hkeS9DNgzm+jSZIOPIaNJKlzho0kqXOGjSSpc4aNJKlzho0kqXOG\njSSpc4aNJKlzho0kqXOGjSSpc4aNJKlzho0kqXOGjSSpc4aNJKlzho0kqXOGjSSpc4aNJKlzho0k\nqXMjC5sk85LclOT/tPklSa5Lsj3JZ5Mc1OoHt/mJtnxx3zbObvW7kpzQV1/VahNJ1s31sUmSftoo\nr2zeBdzZN38ecH5VLQV2AWe2+pnArqp6BXB+a0eSZcCpwKuAVcDHW4DNAz4GnAgsA05rbSVJIzKS\nsEmyCHgz8Mk2H+CNwBWtyUbg5Da9us3Tlh/f2q8GLquqJ6rqHmACOK69Jqrq7qp6EristZUkjcio\nrmz+DPhD4Edt/sXA96vqqTY/CRzVpo8C7gdoyx9p7X9c322dPdUlSSMy52GT5DeBh6vqxv7ygKa1\nj2XTrQ/qy9ok25Js27Fjx156LUmajVFc2bweeEuSe+nd4nojvSudQ5PMb20WAQ+06UngaIC2/EXA\nzv76buvsqf4MVXVRVS2vquULFy6c/ZFJkgaa87CpqrOralFVLab3Af9Xqup3gK8Cb2vN1gBXtulN\nbZ62/CtVVa1+ahuttgRYClwP3AAsbaPbDmr72DQHhyZJ2oP5+24yZ94DXJbkw8BNwMWtfjFwaZIJ\nelc0pwJU1e1JLgfuAJ4CzqqqpwGSvBPYAswDNlTV7XN6JJKknzLSsKmqvwb+uk3fTW8k2e5tfgic\nsof1zwHOGVDfDGzej12VJM2CTxCQJHXOsJEkdc6wkSR1zrCRJHXOsJEkdc6wkSR1zrCRJHXOsJEk\ndc6wkSR1zrCRJHXOsJEkdc6wkSR1zrCRJHXOsJEkdc6wkSR1zrCRJHXOsJEkdc6wkSR1zrCRJHVu\nzsMmydFJvprkziS3J3lXqx+WZGuS7e19QasnyQVJJpLckuTYvm2tae23J1nTV39tklvbOhckyVwf\npyTpJ0ZxZfMU8F+r6peBFcBZSZYB64Crq2opcHWbBzgRWNpea4ELoRdOwHrgdcBxwPqpgGpt1vat\nt2oOjkuStAdzHjZV9WBVfb1NPwbcCRwFrAY2tmYbgZPb9Grgkuq5Fjg0yZHACcDWqtpZVbuArcCq\ntuyQqrqmqgq4pG9bkqQRGOlnNkkWA68BrgNeUlUPQi+QgCNas6OA+/tWm2y1vdUnB9QH7X9tkm1J\ntu3YsWO2hyNJ2oORhU2Snwc+D7y7qh7dW9MBtZpB/ZnFqouqanlVLV+4cOG+uixJmqGRhE2S59IL\nmk9X1Rda+aF2C4z2/nCrTwJH962+CHhgH/VFA+qSpBEZxWi0ABcDd1bVR/oWbQKmRpStAa7sq5/e\nRqWtAB5pt9m2ACuTLGgDA1YCW9qyx5KsaPs6vW9bkqQRmD+Cfb4e+LfArUlubrX3AucClyc5E7gP\nOKUt2wycBEwAjwNnAFTVziQfAm5o7T5YVTvb9DuATwHPB65qL0nSiMx52FTV3zL4cxWA4we0L+Cs\nPWxrA7BhQH0bcMwsuilJ2o98goAkqXOGjSSpc4aNJKlzho0kqXOGjSSpc4aNJKlzho0kqXOGjSSp\nc4aNJKlzho0kqXOGjSSpc4aNJKlzho0kqXOGjSSpc6P4PhvtR4vXfWkk+7333DePZL+Snp28spEk\ndc6wkSR1zrCRJHVubMMmyaokdyWZSLJu1P2RpAPZWIZNknnAx4ATgWXAaUmWjbZXknTgGtfRaMcB\nE1V1N0CSy4DVwB0j7dUYGdUouFFyBJ40c2N5ZQMcBdzfNz/ZapKkERjXK5sMqNUzGiVrgbVt9u+T\n3DXD/R0OfHeG646TsT4POW+oZmN9DqbB89BzIJyHXxym0biGzSRwdN/8IuCB3RtV1UXARbPdWZJt\nVbV8ttt5tvM8eA6meB56PA8/Ma630W4AliZZkuQg4FRg04j7JEkHrLG8sqmqp5K8E9gCzAM2VNXt\nI+6WJB2wxjJsAKpqM7B5jnY361txY8Lz4DmY4nno8Tw0qXrG5+aSJO1X4/qZjSTpZ4hhM0sH0mNx\nktyb5NYkNyfZ1mqHJdmaZHt7X9DqSXJBOy+3JDl2tL2fuSQbkjyc5La+2rSPO8ma1n57kjWjOJaZ\n2sM5+ECS77Sfh5uTnNS37Ox2Du5KckJf/Vn9+5Lk6CRfTXJnktuTvKvVD6ifhxmpKl8zfNEbfPBt\n4GXAQcA3gGWj7leHx3svcPhutT8G1rXpdcB5bfok4Cp6f/O0Arhu1P2fxXG/ATgWuG2mxw0cBtzd\n3he06QWjPrZZnoMPAH8woO2y9rtwMLCk/Y7MG4ffF+BI4Ng2/ULgW+14D6ifh5m8vLKZnR8/Fqeq\nngSmHotzIFkNbGzTG4GT++qXVM+1wKFJjhxFB2erqr4G7NytPN3jPgHYWlU7q2oXsBVY1X3v9489\nnIM9WQ1cVlVPVNU9wAS935Vn/e9LVT1YVV9v048Bd9J7OskB9fMwE4bN7Bxoj8Up4K+S3NievgDw\nkqp6EHq/iMARrT7u52a6xz2u5+Od7fbQhqlbRxwg5yDJYuA1wHX487BPhs3sDPVYnDHy+qo6lt7T\ntM9K8oa9tD3Qzs2UPR33OJ6PC4GXA/8UeBD401Yf+3OQ5OeBzwPvrqpH99Z0QG2szsWwDJvZGeqx\nOOOiqh5o7w8DX6R3W+Shqdtj7f3h1nzcz810j3vszkdVPVRVT1fVj4BP0Pt5gDE/B0meSy9oPl1V\nX2jlA/7nYV8Mm9k5YB6Lk+TnkrxwahpYCdxG73inRtKsAa5s05uA09tonBXAI1O3GcbEdI97C7Ay\nyYJ2u2llqz1r7fYZ3Fvp/TxA7xycmuTgJEuApcD1jMHvS5IAFwN3VtVH+hYd8D8P+zTqEQrP9he9\n0SbfojfK5n2j7k+Hx/kyeqOHvgHcPnWswIuBq4Ht7f2wVg+9L7D7NnArsHzUxzCLY/8MvdtE/0jv\nf6RnzuS4gbfT+7B8Ajhj1Me1H87Bpe0Yb6H3j+qRfe3f187BXcCJffVn9e8L8Gv0bnfdAtzcXicd\naD8PM3n5BAFJUue8jSZJ6pxhI0nqnGEjSeqcYSNJ6pxhI0nqnGEjSeqcYSNJ6pxhI0nq3P8HO1zU\nu8EHYxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24f8f588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.comment_text.apply(lambda txt: len(txt.split(' '))).plot.hist()\n",
    "print('평균적인 vocab의 숫자 : {:.2f}'.format(np.mean(df.comment_text.apply(lambda txt: len(txt.split(' '))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length =  200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_list = list(set([corpus.lower() for list_ in df.comment_text.apply(lambda x : x.split('\\n')) for line in list_ for corpus in line.split()]))\n",
    "voca2int = {voca: idx for idx, voca in zip(voca_list, range(1, len(voca_list) + 1 ))}\n",
    "int2voca = {idx: voca for idx, voca in zip(voca_list, range(1, len(voca_list) + 1 ))}\n",
    "voca2int['<pad>'] = 0\n",
    "int2voca[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'int2voca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-64e8a90b414b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_learning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHparam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-64e8a90b414b>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHparam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint2voca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_unit_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'int2voca' is not defined"
     ]
    }
   ],
   "source": [
    "class Hparam(object):\n",
    "    def __init__(self):\n",
    "        self.vocab_size = len(int2voca)\n",
    "        self.embedding_size = 100\n",
    "        self.rnn_unit_1 = 128\n",
    "        self.rnn_unit_2 = 256\n",
    "        self.dense_unit = 128\n",
    "        self.init_learning_rate = 0.01\n",
    "\n",
    "hparam = Hparam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(object):\n",
    "    def __init__(self, inputs, labels, eval_inputs, eval_labels, data_init, hparam):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        self.data_init = data_init\n",
    "\n",
    "        self.vocab_size = hparam.vocab_size\n",
    "        self.embedding_size = hparam.embedding_size\n",
    "        self.rnn_unit_1 = hparam.rnn_unit_1\n",
    "        self.rnn_unit_2 = hparam.rnn_unit_2\n",
    "        self.dense_unit = hparam.dense_unit\n",
    "        self.init_learning_rate = hparam.init_learning_rate\n",
    "        \n",
    "        self._build()\n",
    "        self._init_step_and_epoch()\n",
    "        self._init_saver()\n",
    "        \n",
    "    def _build():\n",
    "        \"\"\"Build tensorflow graph\"\"\"\n",
    "        \n",
    "        # 2-D tensor [B, T] inputs\n",
    "        with tf.variable_scope('Embed'):\n",
    "            \n",
    "            embed = tf.contrib.layers.embed_sequence(ids=self.inputs,\n",
    "                                                     vocab_size=self.vocab_size, \n",
    "                                                     embed_dim=embedding_size)\n",
    "            \n",
    "        # now 3-D tensor [B, T, C]\n",
    "        with tf.variable_scope('RNN'):\n",
    "            rnn_layers = [tf.contrib.rnn.BasicLSTMCell(size, activation=tf.nn.sigmoid) for size in [self.rnn_unit_1, self.rnn_unit2]]\n",
    "            self.cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.MultiRNNCell(rnn_layers))\n",
    "            _, state = tf.nn.dynamic_rnn(cell=cell, inputs=embed)\n",
    "                    \n",
    "        with tf.variable_scope('Dense'):\n",
    "            layer1= tf.layers.batch_normalization(tf.layers.dense(state,self.dense_unit, activation=tf.nn.sigmoid))\n",
    "            self.logits = tf.layers.dense(layer1, 2, activation=None)\n",
    "            \n",
    "        self.learning_rate = tf.train.exponential_decay(self.init_learning_rate, \n",
    "                                                        self.global_step, \n",
    "                                                        decay_steps=1000, \n",
    "                                                        decay_rate=0.9)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(targets=tf.one_hot(self.labels, depth=2), \n",
    "                                                                            logits=self.logits, \n",
    "                                                                            pos_weight=3.0))\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        \n",
    "        gvs = self.optimizer.compute_gradients(self.loss, \n",
    "                                               tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "        \n",
    "        cliped_grad = [(tf.clip_by_value(grad, -1.,1.), var) for grad, var in gvs]\n",
    "        self.train_op = self.optimizer.apply_gradient(cliped_grad, global_step = self.global_step)\n",
    "        \n",
    "        \n",
    "        self.prediction = tf.argmax(self.logits, axis=-1)    \n",
    "        self.accuracy = tf.reduce_mean(tf.equal(self.prediction, self.labels), name='accuracy')\n",
    "        \n",
    "        # metrics : [Loss, accuracy]\n",
    "        tf.summary.scalar(self.accuracy)\n",
    "        tf.summary.scalar(self.loss)\n",
    "        self.merge = tf.summary.merge_all()\n",
    "        \n",
    "    def _init_saver():\n",
    "        self.saver = tf.train.Saver(var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n",
    "        \n",
    "    def _init_step_and_epoch():\n",
    "        self.global_step = tf.get_variable('global_step', initializer=tf.constant_initializer(0))\n",
    "        self.epoch = tf.get_variable('epoch', initializer=tf.constant_initializer(0))\n",
    "        \n",
    "    def train(self, sess, epoch):\n",
    "        sess.run([tf.global_variables_initializer(), self.data_init])\n",
    "        \n",
    "        while(1):\n",
    "            try:\n",
    "                sess.run(self.train_op)\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                self.epoch = tf.add(self.epoch, 1)\n",
    "                sess.run([self.data_init, self.merge])\n",
    "\n",
    "    def evaluate(self, sess):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        pass\n",
    "    \n",
    "    def save():\n",
    "        saver.save(sess, './ckpt/{}_epoch'.format(e)) \n",
    "        print('Graph is saved')\n",
    "    \n",
    "    def load():\n",
    "        self.saver.restore(sess, tf.train.latest_checkpoint('./ckpt'))    \n",
    "        print('Graph is loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 구글에서 미리 트레이닝시켜 놓은 word2vec을 이용하여 300차원으로 Embedding 시킨다.  \n",
    "이 후에 LSTM cell을 이용한 RNN 을 이용하여 문장을 Encoding 시킨 후 Dense network를 이용하여 Classify 해보자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
